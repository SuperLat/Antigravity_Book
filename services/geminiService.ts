import { GoogleGenAI } from "@google/genai";
import { Entity, Chapter, EntityType, ModelConfig, ChapterBeat, BeatsSplit, CharacterProfile } from '../types';

// Default env key
const DEFAULT_API_KEY = process.env.API_KEY || '';

let geminiClient: GoogleGenAI | null = null;
let currentGeminiKey: string | null = null;

const initializeGemini = (apiKey?: string) => {
  const keyToUse = apiKey || DEFAULT_API_KEY;
  if (keyToUse && keyToUse !== currentGeminiKey) {
    geminiClient = new GoogleGenAI({ apiKey: keyToUse });
    currentGeminiKey = keyToUse;
  }
};

// Retry utility with exponential backoff
async function retryWithBackoff<T>(
  fn: () => Promise<T>,
  retries = 3,
  delay = 1000,
  backoff = 2
): Promise<T> {
  try {
    return await fn();
  } catch (error: any) {
    // Check for 429 (Too Many Requests) or 503 (Service Unavailable)
    const isRateLimit = error.status === 429 ||
      (error.message && error.message.includes('429')) ||
      (error.message && error.message.includes('RESOURCE_EXHAUSTED'));

    if (retries > 0 && isRateLimit) {
      console.warn(`âš ï¸ API Rate Limit hit. Retrying in ${delay}ms... (${retries} retries left)`);
      await new Promise(resolve => setTimeout(resolve, delay));
      return retryWithBackoff(fn, retries - 1, delay * backoff, backoff);
    }

    if (isRateLimit) {
      throw new Error('API è°ƒç”¨æ¬¡æ•°è¶…é™ï¼Œå·²é‡è¯•å¤šæ¬¡æ— æ•ˆã€‚è¯·æ£€æŸ¥æ‚¨çš„ API é…é¢æˆ–ç¨åå†è¯•ã€‚');
    }
    throw error;
  }
}

// OpenAI-compatible API call (for DeepSeek, OpenAI, etc.)
const callOpenAICompatible = async (
  modelConfig: ModelConfig,
  messages: Array<{ role: string; content: string }>,
  systemInstruction?: string
): Promise<string> => {
  // Use proxy for CORS issues
  let baseUrl = modelConfig.baseUrl || '';
  let useBackendProxy = false;

  // If no custom URL, use proxy
  if (!baseUrl) {
    if (modelConfig.provider === 'openai') {
      baseUrl = '/api/openai/v1';
    } else if (modelConfig.provider === 'custom') {
      baseUrl = '/api/deepseek';
    } else if (modelConfig.provider === 'gemini') {
      baseUrl = '/v1beta/openai/';
    }
  } else {
    // If it's a custom absolute URL, use our backend proxy
    if (baseUrl.startsWith('http')) {
      useBackendProxy = true;
    }
  }

  const requestBody: any = {
    model: modelConfig.modelName,
    messages: systemInstruction
      ? [{ role: 'system', content: systemInstruction }, ...messages]
      : messages,
    temperature: modelConfig.temperature,
    max_tokens: modelConfig.maxTokens,
  };

  // --- ç«å±±å¼•æ“/DeepSeek ç‰¹æœ‰é…ç½®å¼€å…³ ---
  // ä½¿ç”¨å‰ç«¯ä¼ å…¥çš„é…ç½®ï¼Œé»˜è®¤ä¸º false (disabled)
  const ENABLE_DEEPSEEK_THINKING = modelConfig.enableThinking ?? false;

  // æ£€æµ‹æ˜¯å¦ä¸º DeepSeek ç³»åˆ—æ¨¡å‹ (å…¼å®¹ deekseep æ‹¼å†™)
  const isDeepSeek = /deepseek|deekseep/i.test(modelConfig.modelName);

  if (isDeepSeek) {
    // ç«å±±å¼•æ“ç‰¹å®šå‚æ•°: æ§åˆ¶æ€è€ƒæ¨¡å¼
    // åªæœ‰åœ¨å¯ç”¨æ—¶æ‰å‘é€ thinking å‚æ•°ï¼Œå¦åˆ™ä¸å‘é€ï¼ˆä¾èµ–é»˜è®¤å…³é—­ï¼‰
    if (ENABLE_DEEPSEEK_THINKING) {
      requestBody.thinking = {
        type: "enabled"
      };
    }
    console.log(`ğŸ§  DeepSeek æ€è€ƒæ¨¡å¼: ${ENABLE_DEEPSEEK_THINKING ? 'å·²å¯ç”¨' : 'å·²ç¦ç”¨'}`);
  }
  // ------------------------------------

  console.log('ğŸš€ API è¯·æ±‚:', {
    url: useBackendProxy ? '/api/proxy' : `${baseUrl}/chat/completions`,
    targetUrl: useBackendProxy ? `${baseUrl}/chat/completions` : undefined,
    provider: modelConfig.provider,
    model: modelConfig.modelName,
  });

  try {
    const fetchUrl = useBackendProxy ? '/api/proxy' : `${baseUrl}/chat/completions`;
    const fetchOptions: RequestInit = {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${modelConfig.apiKey}`,
      },
      body: JSON.stringify(useBackendProxy ? {
        targetUrl: `${baseUrl}/chat/completions`,
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${modelConfig.apiKey.trim()}`,
        },
        body: requestBody
      } : requestBody),
    };

    const response = await retryWithBackoff(() => fetch(fetchUrl, fetchOptions));

    if (!response.ok) {
      const errorText = await response.text();
      console.error('âŒ API é”™è¯¯å“åº”:', errorText);
      let errorMessage = `HTTP ${response.status}: ${response.statusText}`;
      try {
        const errorJson = JSON.parse(errorText);
        errorMessage = errorJson.error?.message || errorJson.message || errorMessage;
      } catch (e) {
        errorMessage = errorText || errorMessage;
      }
      throw new Error(errorMessage);
    }

    const data = await response.json();
    console.log('âœ… API å“åº”æˆåŠŸ');
    return data.choices[0]?.message?.content || 'æœªèƒ½ç”Ÿæˆå†…å®¹ã€‚';
  } catch (error: any) {
    console.error('âŒ API è°ƒç”¨å¤±è´¥:', error);
    if (error.message === 'Failed to fetch') {
      throw new Error('ç½‘ç»œè¯·æ±‚å¤±è´¥ã€‚è¯·æ£€æŸ¥ï¼š\n1. API Key æ˜¯å¦æ­£ç¡®\n2. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸\n3. API æœåŠ¡æ˜¯å¦å¯ç”¨');
    }
    throw error;
  }
};

// Test model configuration
export const testModelConfig = async (modelConfig: ModelConfig): Promise<{ success: boolean; message: string }> => {
  try {
    console.log('ğŸ§ª æµ‹è¯•æ¨¡å‹é…ç½®:', modelConfig.name);

    if (modelConfig.provider === 'gemini') {
      initializeGemini(modelConfig.apiKey);
      if (!geminiClient) {
        return { success: false, message: 'API Key æœªé…ç½®' };
      }

      const response = await retryWithBackoff(() => geminiClient!.models.generateContent({
        model: modelConfig.modelName || 'gemini-2.5-flash',
        contents: 'è¯·å›å¤"æµ‹è¯•æˆåŠŸ"',
        config: {
          temperature: 0.1,
          maxOutputTokens: 50,
        }
      }));

      const result = response.text || '';
      return {
        success: true,
        message: `âœ… è¿æ¥æˆåŠŸï¼\næ¨¡å‹å“åº”: ${result.substring(0, 50)}${result.length > 50 ? '...' : ''}`
      };
    } else {
      const result = await retryWithBackoff(() => callOpenAICompatible(
        modelConfig,
        [{ role: 'user', content: 'è¯·å›å¤"æµ‹è¯•æˆåŠŸ"' }],
        'ä½ æ˜¯ä¸€ä¸ªæµ‹è¯•åŠ©æ‰‹ï¼Œè¯·ç®€çŸ­å›å¤ã€‚'
      ));

      return {
        success: true,
        message: `âœ… è¿æ¥æˆåŠŸï¼\næ¨¡å‹å“åº”: ${result.substring(0, 50)}${result.length > 50 ? '...' : ''}`
      };
    }
  } catch (error: any) {
    console.error('âŒ æµ‹è¯•å¤±è´¥:', error);
    return {
      success: false,
      message: `âŒ æµ‹è¯•å¤±è´¥\né”™è¯¯: ${error.message}`
    };
  }
};

export const generateVolumesFromOutline = async (

  config: ModelConfig,

  outline: string,

  customTemplate?: string

): Promise<{ title: string; summary: string }[]> => {

  // 1. Strict Regex Extraction (No AI)

  // We use local extraction to avoid Token limits and ensure exact fidelity to the outline.

  const volumes: { title: string; summary: string }[] = [];



  // Regex to match headers.

  // Supports:

  // - Markdown headers: #, ##, ###

  // - Plain text starts

  // - Patterns: "ç¬¬xå·", "Volume x", "å·x"

  const headerRegex = /^\s*(?:#{1,6}\s*)?.*(?:ç¬¬[0-9é›¶ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾]+å·|Volume\s*\d+|å·[0-9é›¶ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾]+).*$/gmi;



  const matches = [...outline.matchAll(headerRegex)];



  if (matches.length > 0) {

    for (let i = 0; i < matches.length; i++) {

      const match = matches[i];

      // Clean up title (remove leading hashes and whitespace)

      const title = match[0].replace(/^[#\s]+/, '').trim();



      const startIndex = match.index! + match[0].length;

      const endIndex = (i < matches.length - 1) ? matches[i + 1].index! : outline.length;



      const summary = outline.substring(startIndex, endIndex).trim();



      if (title) {

        volumes.push({ title, summary });

      }

    }

  }



  if (volumes.length === 0) {

    console.warn("No volumes found via Regex extraction in outline:", outline.substring(0, 100));

    throw new Error("æ— æ³•ä»å¤§çº²ä¸­æå–åˆ†å·ä¿¡æ¯ã€‚\n\nè¯·ç¡®ä¿å¤§çº²åŒ…å«æ¸…æ™°çš„åˆ†å·æ ‡é¢˜ï¼Œä¾‹å¦‚ï¼š\nâ€œ### ç¬¬ä¸€å·ï¼šé£èµ·äº‘æ¶Œâ€\nâ€œ# å·ä¸€ åˆå§‹â€\nâ€œVolume 1: The Beginningâ€");

  }



  console.log(`âœ… Successfully extracted ${volumes.length} volumes via Regex.`);

  return volumes;

};

export const generatePartsFromVolume = async (
  config: ModelConfig,
  volumeTitle: string,
  volumeSummary: string,
  customTemplate?: string
): Promise<{ title: string; summary: string }[]> => {
  const prompt = customTemplate
    ? customTemplate.replace('{{volumeTitle}}', volumeTitle).replace('{{volumeSummary}}', volumeSummary)
    : `
ä½œä¸ºä¸€åèµ„æ·±ç½‘æ–‡ç­–åˆ’ï¼Œè¯·æ ¹æ®ä»¥ä¸‹å·å¤§çº²ï¼Œå°†å…¶æ‹†åˆ†ä¸º 2-4 ä¸ª"åˆ†éƒ¨"ï¼ˆPartï¼‰ã€‚
æ¯ä¸ªåˆ†éƒ¨åº”è¯¥æ˜¯è¯¥å·å†…çš„ä¸€ä¸ªé˜¶æ®µæ€§å‰§æƒ…å•å…ƒï¼Œæœ‰æ˜ç¡®çš„èµ·æ‰¿è½¬åˆã€‚

å·æ ‡é¢˜ï¼š${volumeTitle}
å·å¤§çº²ï¼š
${volumeSummary}

è¯·ä»¥ JSON æ•°ç»„æ ¼å¼è¿”å›ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
[
  {
    "title": "ç¬¬ä¸€éƒ¨ï¼šåˆ†éƒ¨å",
    "summary": "æœ¬åˆ†éƒ¨çš„è¯¦ç»†å‰§æƒ…æ‘˜è¦..."
  },
  ...
]
åªè¿”å› JSON æ•°æ®ï¼Œä¸è¦åŒ…å« markdown æ ‡è®°æˆ–å…¶ä»–æ–‡æœ¬ã€‚
`;

  const systemInstruction = "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å°è¯´ç­–åˆ’å¸ˆã€‚è¯·æ ¹æ®ç”¨æˆ·æä¾›çš„å·å¤§çº²ï¼Œå°†å…¶æ‹†åˆ†ä¸ºå¤šä¸ªåˆ†éƒ¨ã€‚";

  try {
    let text = '';
    if (config.provider === 'gemini') {
      initializeGemini(config.apiKey);
      if (!geminiClient) throw new Error("API Key missing.");

      const response = await retryWithBackoff(() => geminiClient!.models.generateContent({
        model: config.modelName || 'gemini-2.5-flash',
        contents: prompt,
        config: {
          systemInstruction,
          temperature: 0.8,
          maxOutputTokens: 4096,
        }
      }));
      text = response.text || "";
    } else {
      text = await retryWithBackoff(() => callOpenAICompatible(
        config,
        [{ role: 'user', content: prompt }],
        systemInstruction
      ));
    }

    try {
      const jsonStr = text.replace(/```json\n?|\n?```/g, '').trim();
      return JSON.parse(jsonStr);
    } catch (e) {
      console.error("Failed to parse parts JSON", text);
      throw new Error("AI è¿”å›æ ¼å¼é”™è¯¯ï¼Œæ— æ³•è§£æåˆ†éƒ¨æ•°æ®ã€‚");
    }
  } catch (error) {
    throw new Error(`ç”Ÿæˆåˆ†éƒ¨å¤±è´¥: ${(error as Error).message}`);
  }
};

// Generate chapter summary
export const generateChapterSummary = async (
  modelConfig: ModelConfig,
  chapterContent: string,
  customTemplate?: string
): Promise<string> => {
  let finalPrompt = '';

  if (customTemplate) {
    finalPrompt = customTemplate
      .replace(/{{content}}/g, chapterContent)
      .replace(/{{input}}/g, chapterContent);
  } else {
    finalPrompt = `
      è¯·ä¸ºä»¥ä¸‹ç« èŠ‚å†…å®¹ç”Ÿæˆä¸€ä¸ªç®€æ´çš„æ¦‚è¦ï¼ˆ100-200å­—ï¼‰ï¼š

      ã€ç« èŠ‚å†…å®¹ã€‘
      ${chapterContent}

      è¦æ±‚ï¼š
      1. æ¦‚æ‹¬æœ¬ç« çš„æ ¸å¿ƒäº‹ä»¶å’Œæƒ…èŠ‚å‘å±•
      2. æåŠå…³é”®è§’è‰²å’Œä»–ä»¬çš„è¡ŒåŠ¨
      3. çªå‡ºæœ¬ç« çš„å†²çªæˆ–è½¬æŠ˜ç‚¹
      4. ç®€æ˜æ‰¼è¦ï¼Œä¾¿äºåç»­ç« èŠ‚å‚è€ƒ

      è¯·ç›´æ¥è¾“å‡ºæ¦‚è¦å†…å®¹ï¼Œä¸è¦åŒ…å«å…¶ä»–è¯´æ˜ã€‚
    `;
  }

  const systemInstruction = "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å°è¯´ç¼–è¾‘ã€‚è¯·ä¸ºç« èŠ‚å†…å®¹ç”Ÿæˆç²¾ç‚¼çš„æ¦‚è¦ï¼Œå¸®åŠ©ä½œè€…æŠŠæ¡æ•…äº‹è„‰ç»œã€‚";

  try {
    if (modelConfig.provider === 'gemini') {
      initializeGemini(modelConfig.apiKey);
      if (!geminiClient) throw new Error("API Key missing.");

      const response = await retryWithBackoff(() => geminiClient!.models.generateContent({
        model: modelConfig.modelName || 'gemini-2.5-flash',
        contents: finalPrompt,
        config: {
          systemInstruction,
          temperature: 0.5,
          maxOutputTokens: 500,
        }
      }));
      return response.text || "æœªèƒ½ç”Ÿæˆæ¦‚è¦ã€‚";
    } else {
      return await callOpenAICompatible(
        modelConfig,
        [{ role: 'user', content: finalPrompt }],
        systemInstruction
      );
    }
  } catch (error) {
    throw new Error(`ç”Ÿæˆæ¦‚è¦å¤±è´¥: ${(error as Error).message}`);
  }
};

interface GenerationParams {
  modelConfig: ModelConfig;
  userPrompt: string;
  selectedEntities: Entity[];
  selectedChapters: Chapter[];
  activeChapter: Chapter;
  previousChapterSummary?: string;
}

const getTypeLabel = (type: EntityType) => {
  switch (type) {
    case EntityType.CHARACTER: return 'è§’è‰²è®¾å®š';
    case EntityType.WORLDVIEW: return 'ä¸–ç•Œè§‚è®¾å®š';
    case EntityType.PLOT: return 'å‰§æƒ…å¤§çº²';
    case EntityType.IDEA: return 'çµæ„Ÿ/è„‘æ´';
    default: return 'è®¾å®š';
  }
}

export const generateNovelContent = async ({
  modelConfig,
  userPrompt,
  selectedEntities,
  selectedChapters,
  activeChapter,
  previousChapterSummary
}: GenerationParams): Promise<string> => {

  // 1. Construct the System Context from selected Wiki items
  const contextBlock = selectedEntities.map(e =>
    `ã€${getTypeLabel(e.type)} - ${e.name}ã€‘\nç®€ä»‹ï¼š${e.description}\nè¯¦ç»†å†…å®¹ï¼š${e.content}`
  ).join('\n\n');

  // 1.5 Construct Context from selected Chapters (Limit content length to avoid token overflow)
  const chapterBlock = selectedChapters.map(c => {
    // Take the last 3000 characters of the referenced chapter to keep context relevant but manageable
    const contentPreview = c.content.length > 3000
      ? `...(å‰æ–‡çœç•¥)\n${c.content.slice(-3000)}`
      : c.content;
    return `ã€å‚è€ƒç« èŠ‚ - ${c.title}ã€‘\n${contentPreview}`;
  }).join('\n\n');

  // 2. Construct Writing Context (Current Story State)
  // Increase context window for current chapter to ensure continuity
  const storyContext = `
    ã€å‰æƒ…æè¦ã€‘: ${previousChapterSummary || "æš‚æ— "}
    ã€å½“å‰ç« èŠ‚å†…å®¹ (ç»­å†™èµ·ç‚¹)ã€‘: 
    ${activeChapter.content.slice(-3000)} 
    ... (ä»¥ä¸Šä¸ºå½“å‰æ­£æ–‡æœ«å°¾)
  `;

  // 3. Final Prompt Assembly
  const finalPrompt = `
    ${contextBlock ? `--- å…³è”çš„çŸ¥è¯†åº“ (Wiki) ---\n${contextBlock}\n------------------------------` : ''}
    
    ${chapterBlock ? `--- å…³è”çš„ç« èŠ‚ (å‰æ–‡å‚è€ƒ) ---\n${chapterBlock}\n------------------------------` : ''}

    ${storyContext}

    --- ä½ çš„ä»»åŠ¡ ---
    ${userPrompt}
    
    (è¯·ç»§ç»­æ’°å†™æ­£æ–‡ï¼Œä¿æŒé£æ ¼ä¸€è‡´ï¼Œæƒ…èŠ‚è¿è´¯ã€‚)
  `;

  const systemInstruction = "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å°è¯´å®¶åŠ©æ‰‹ã€‚ä½ çš„ç›®æ ‡æ˜¯åŸºäºæä¾›çš„ä¸–ç•Œè§‚ã€è§’è‰²è®¾å®šå’Œå‰æ–‡ç« èŠ‚ï¼Œè¾…åŠ©ç”¨æˆ·è¿›è¡Œå°è¯´åˆ›ä½œã€æ‰©å†™æˆ–æ¶¦è‰²ã€‚è¯·åŠ¡å¿…ä¿æŒç°æœ‰æ–‡æœ¬çš„é£æ ¼å’Œè¯­æ°”ã€‚æ‰€æœ‰è¾“å‡ºé»˜è®¤ä½¿ç”¨ä¸­æ–‡ã€‚";

  try {
    // Route to different providers
    if (modelConfig.provider === 'gemini') {
      initializeGemini(modelConfig.apiKey);
      if (!geminiClient) throw new Error("API Key missing. Please configure it in Settings.");

      const response = await retryWithBackoff(() => geminiClient!.models.generateContent({
        model: modelConfig.modelName || 'gemini-2.5-flash',
        contents: finalPrompt,
        config: {
          systemInstruction,
          temperature: modelConfig.temperature,
          maxOutputTokens: Math.max(modelConfig.maxTokens || 2048, 4096), // Ensure sufficient output tokens for writing
        }
      }));
      return response.text || "æœªèƒ½ç”Ÿæˆå†…å®¹ã€‚";
    } else if (modelConfig.provider === 'openai' || modelConfig.provider === 'custom') {
      return await callOpenAICompatible(
        { ...modelConfig, maxTokens: Math.max(modelConfig.maxTokens || 2048, 4096) }, // Override maxTokens locally
        [{ role: 'user', content: finalPrompt }],
        systemInstruction
      );
    } else if (modelConfig.provider === 'ollama') {
      // Ollama uses OpenAI-compatible API
      return await callOpenAICompatible(
        { ...modelConfig, baseUrl: modelConfig.baseUrl || 'http://localhost:11434/v1', maxTokens: Math.max(modelConfig.maxTokens || 2048, 4096) },
        [{ role: 'user', content: finalPrompt }],
        systemInstruction
      );
    } else {
      throw new Error(`ä¸æ”¯æŒçš„æä¾›å•†: ${modelConfig.provider}`);
    }
  } catch (error) {
    console.error("AI Generation Error:", error);
    return `ç”Ÿæˆå†…å®¹æ—¶å‡ºé”™: ${(error as Error).message}`;
  }
};

// Helper to extract JSON from AI response
const extractJson = (text: string): string => {
  // 1. Try to find content within ```json ... ``` blocks
  const markdownMatch = text.match(/```(?:json)?\s*([\s\S]*?)\s*```/i);
  if (markdownMatch && markdownMatch[1]) {
    return markdownMatch[1].trim();
  }

  // 2. Try to find the first '{' and last '}'
  const braceMatch = text.match(/\{[\s\S]*\}/);
  if (braceMatch) {
    return braceMatch[0].trim();
  }

  return text.trim();
};

export const generateStoryCoreAndSynopsis = async (
  modelConfig: ModelConfig,
  spark: string,
  options?: {
    length?: string;
    genre?: string;
    background?: string;
  },
  customTemplate?: string
): Promise<{ core: string; synopsis: string }> => {
  let finalPrompt = '';

  const optionsText = `
${options?.length ? `- ç¯‡å¹…æœŸæœ›ï¼š${options.length === 'long' ? 'é•¿ç¯‡å°è¯´' : 'çŸ­ç¯‡æ•…äº‹'}` : ''}
${options?.genre ? `- æ•…äº‹ç±»å‹ï¼š${options.genre}` : ''}
${options?.background ? `- æ•…äº‹èƒŒæ™¯ï¼š${options.background}` : ''}
  `.trim();

  if (customTemplate) {
    finalPrompt = customTemplate
      .replace(/{{input}}/g, spark)
      .replace(/{{spark}}/g, spark)
      .replace(/{{options}}/g, optionsText);
  } else {
    finalPrompt = `
      ã€æ ¸å¿ƒè„‘æ´/çµæ„Ÿã€‘ï¼š${spark}
      ${optionsText ? `\nã€åˆ›ä½œè®¾å®šã€‘ï¼š\n${optionsText}\n` : ''}
      
      è¯·åŸºäºä»¥ä¸Šä¿¡æ¯ï¼Œæç‚¼å‡ºæ•…äº‹å†…æ ¸ï¼ˆStory Coreï¼‰å¹¶æ’°å†™ä¸€ä¸ªæ•…äº‹æ¦‚è¦ï¼ˆStory Synopsisï¼‰ã€‚
      
      è¦æ±‚ï¼š
      1. æ•…äº‹å†…æ ¸ï¼šç”¨ä¸€å¥è¯æˆ–ç®€çŸ­çš„å‡ å¥è¯æè¿°æ•…äº‹æœ€æ·±å±‚çš„å“²å­¦å†…æ¶µã€æƒ…æ„Ÿæ ¸å¿ƒæˆ–æœ€æœ¬è´¨çš„å†²çªã€‚
      2. æ•…äº‹æ¦‚è¦ï¼šçº¦ 300-500 å­—ï¼ŒåŒ…å«èƒŒæ™¯è®¾å®šã€ä¸»è§’åŠ¨æœºã€æ ¸å¿ƒå±æœºä»¥åŠå¤§è‡´çš„å‘å±•æ–¹å‘ã€‚
      
      è¯·ä¸¥æ ¼ä»¥ JSON æ ¼å¼è¿”å›ï¼Œä¸è¦åŒ…å«ä»»ä½• markdown ä»£ç å—æ ‡è®°ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
      {
        "core": "æ•…äº‹å†…æ ¸å†…å®¹...",
        "synopsis": "æ•…äº‹æ¦‚è¦å†…å®¹..."
      }
    `;
  }

  const systemInstruction = "ä½ æ˜¯ä¸€ä¸ªæ“…é•¿æç‚¼æ•…äº‹çµé­‚å’Œæ¶æ„å¤§çº²çš„å°è¯´ç­–åˆ’ã€‚è¯·åŠ¡å¿…åªè¿”å› JSON æ•°æ®ï¼Œç¡®ä¿æ ¼å¼æ­£ç¡®ã€‚";

  try {
    let text = '';
    if (modelConfig.provider === 'gemini') {
      initializeGemini(modelConfig.apiKey);
      if (!geminiClient) throw new Error("API Key missing.");

      const response = await retryWithBackoff(() => geminiClient!.models.generateContent({
        model: modelConfig.modelName || 'gemini-2.5-flash',
        contents: finalPrompt,
        config: {
          systemInstruction,
          temperature: 0.8,
          maxOutputTokens: 2048,
          responseMimeType: "application/json"
        }
      }));

      // Handle both property and method access for text
      text = typeof (response as any).text === 'function' ? (response as any).text() : ((response as any).text || "");
    } else {
      text = await retryWithBackoff(() => callOpenAICompatible(
        modelConfig,
        [{ role: 'user', content: finalPrompt }],
        systemInstruction
      ));
    }

    console.log("AI Raw Response:", text);

    try {
      const jsonStr = extractJson(text);
      const data = JSON.parse(jsonStr);

      // Map potential different key names
      return {
        core: data.core || data.storyCore || data.story_core || data.å†…æ ¸ || "",
        synopsis: data.synopsis || data.storySynopsis || data.story_synopsis || data.æ¦‚è¦ || ""
      };
    } catch (e) {
      console.error("Failed to parse core and synopsis JSON. Raw text:", text);
      throw new Error("AI è¿”å›æ ¼å¼é”™è¯¯ï¼Œæ— æ³•è§£ææ•°æ®ã€‚è¯·æ£€æŸ¥æ§åˆ¶å°è¾“å‡ºçš„åŸå§‹å“åº”ã€‚");
    }
  } catch (error) {
    throw new Error(`ç”Ÿæˆæ•…äº‹å†…æ ¸ä¸æ¦‚è¦å¤±è´¥: ${(error as Error).message}`);
  }
};

export const generateStorylineFromIdea = async (
  modelConfig: ModelConfig,
  spark: string,
  core?: string,
  synopsis?: string,
  customTemplate?: string
): Promise<string> => {
  let finalPrompt = '';

  if (customTemplate) {
    finalPrompt = customTemplate
      .replace(/{{input}}/g, spark)
      .replace(/{{spark}}/g, spark)
      .replace(/{{core}}/g, core || '')
      .replace(/{{synopsis}}/g, synopsis || '');
  } else {
    finalPrompt = `
      ã€åŸå§‹çµæ„Ÿã€‘ï¼š${spark}
      ${core ? `ã€æ•…äº‹å†…æ ¸ã€‘ï¼š${core}` : ''}
      ${synopsis ? `ã€æ•…äº‹æ¦‚è¦ã€‘ï¼š${synopsis}` : ''}
      
      è¯·åŸºäºä»¥ä¸Šä¿¡æ¯ï¼Œæ¢³ç†å‡ºä¸€æ¡æ¸…æ™°ã€å®Œæ•´çš„æ•…äº‹çº¿ï¼ˆStorylineï¼‰ã€‚
      
      è¦æ±‚ï¼š
      1. æ˜ç¡®æ•…äº‹çš„ä¸»è§’åŠå…¶æ ¸å¿ƒç›®æ ‡ã€‚
      2. æ¦‚æ‹¬æ•…äº‹çš„èµ·å› ã€ç»è¿‡å’Œç»“æœï¼ˆStart, Middle, Endï¼‰ã€‚
      3. åŒ…å«å…³é”®çš„è½¬æŠ˜ç‚¹å’Œé«˜æ½®äº‹ä»¶ã€‚
      4. æ—¢ç„¶æ˜¯æ•…äº‹çº¿ï¼Œè¯·æ³¨é‡é€»è¾‘è¿è´¯æ€§ï¼Œå­—æ•°æ§åˆ¶åœ¨ 500-800 å­—å·¦å³ã€‚
      
      è¯·ç›´æ¥è¾“å‡ºæ•…äº‹çº¿å†…å®¹ã€‚
    `;
  }

  const systemInstruction = "ä½ æ˜¯ä¸€ä¸ªæ“…é•¿æ¢³ç†æ•…äº‹è„‰ç»œçš„å°è¯´ç­–åˆ’ã€‚è¯·å°†ç”¨æˆ·çš„ç¢ç‰‡åŒ–è„‘æ´è½¬åŒ–ä¸ºè¿è´¯çš„æ•…äº‹çº¿ã€‚";

  try {
    if (modelConfig.provider === 'gemini') {
      initializeGemini(modelConfig.apiKey);
      if (!geminiClient) throw new Error("API Key missing.");

      const response = await retryWithBackoff(() => geminiClient!.models.generateContent({
        model: modelConfig.modelName || 'gemini-2.5-flash',
        contents: finalPrompt,
        config: {
          systemInstruction,
          temperature: 0.8,
          maxOutputTokens: 2048,
        }
      }));
      return response.text || "æœªèƒ½ç”Ÿæˆæ•…äº‹çº¿ã€‚";
    } else {
      return await callOpenAICompatible(
        modelConfig,
        [{ role: 'user', content: finalPrompt }],
        systemInstruction
      );
    }
  } catch (error) {
    throw new Error(`ç”Ÿæˆæ•…äº‹çº¿å¤±è´¥: ${(error as Error).message}`);
  }
};

export const generateOutlineFromStoryline = async (
  modelConfig: ModelConfig,
  storyline: string,
  customTemplate?: string
): Promise<string> => {
  let finalPrompt = '';

  if (customTemplate) {
    finalPrompt = customTemplate
      .replace(/{{storyline}}/g, storyline)
      .replace(/{{input}}/g, storyline);
  } else {
    finalPrompt = `
      ã€æ•…äº‹çº¿ã€‘ï¼š
      ${storyline}

      è¯·åŸºäºä»¥ä¸Šæ•…äº‹çº¿ï¼Œè®¾è®¡ä¸€ä¸ªæ ‡å‡†çš„ç½‘æ–‡å¤§çº²ï¼ˆä¸‰å¹•å¼æˆ–å¤šå·å¼ï¼‰ã€‚
      è¦æ±‚ï¼š
      1. ä¸»è§’äººè®¾ç®€è¿°ï¼ˆåŸºäºæ•…äº‹çº¿æ¨å¯¼ï¼‰ã€‚
      2. è¯¦ç»†è§„åˆ’æ¯ä¸€å¹•/å·çš„æ ¸å¿ƒå†²çªã€å…³é”®å‰§æƒ…ç‚¹å’Œçˆ½ç‚¹ã€‚
      3. ç»“å±€è®¾è®¡ã€‚
      
      è¯·ç”¨ Markdown æ ¼å¼è¾“å‡ºï¼Œç»“æ„æ¸…æ™°ã€‚
    `;
  }

  const systemInstruction = "ä½ æ˜¯ä¸€ä¸ªæ“…é•¿æ„å»ºå‰§æƒ…ç»“æ„çš„å°è¯´ä¸»ç¼–ã€‚è¯·æ ¹æ®æ•…äº‹çº¿ï¼Œè®¾è®¡æƒ…èŠ‚ç´§å‡‘ã€å†²çªæ¿€çƒˆçš„å¤§çº²ã€‚";

  try {
    if (modelConfig.provider === 'gemini') {
      initializeGemini(modelConfig.apiKey);
      if (!geminiClient) throw new Error("API Key missing.");

      const response = await retryWithBackoff(() => geminiClient!.models.generateContent({
        model: modelConfig.modelName || 'gemini-2.5-flash',
        contents: finalPrompt,
        config: {
          systemInstruction,
          temperature: 0.7,
        }
      }));
      return response.text || "æœªèƒ½ç”Ÿæˆå¤§çº²ã€‚";
    } else {
      return await callOpenAICompatible(
        modelConfig,
        [{ role: 'user', content: finalPrompt }],
        systemInstruction
      );
    }
  } catch (error) {
    throw new Error(`ç”Ÿæˆå¤§çº²å¤±è´¥: ${(error as Error).message}`);
  }
};

export const generateWorldviewFromIdea = async (
  modelConfig: ModelConfig,
  ideaContent: string,
  customTemplate?: string
): Promise<string> => {
  let finalPrompt = '';

  if (customTemplate) {
    finalPrompt = customTemplate
      .replace(/{{input}}/g, ideaContent)
      .replace(/{{spark}}/g, ideaContent);
  } else {
    finalPrompt = `
      æ ¸å¿ƒæ¢—/è„‘æ´ï¼šã€${ideaContent}ã€‘
      
      è¯·åŸºäºä¸Šè¿°æ ¸å¿ƒæ¢—ï¼Œè®¾è®¡ä¸€ä¸ªç²¾ç‚¼çš„ä¸–ç•Œè§‚è‰æ¡ˆã€‚
      
      è¦æ±‚åŒ…å«ä»¥ä¸‹å†…å®¹ï¼ˆè¯·ä¿æŒç®€æ˜æ‰¼è¦ï¼‰ï¼š
      1. åŠ›é‡ä½“ç³»åç§°åŠç­‰çº§åˆ’åˆ†ã€‚
      2. ç¤¾ä¼šç»“æ„ä¸æ ¸å¿ƒé˜¶å±‚çŸ›ç›¾ã€‚
      3. æ ¸å¿ƒèƒ½æºæˆ–é©±åŠ¨åŠ›æ˜¯ä»€ä¹ˆã€‚
      4. ç‹¬ç‰¹çš„åœ°ç†ç¯å¢ƒæˆ–åŸå¸‚é£è²Œã€‚
      
      è¯·ä½¿ç”¨ç»“æ„æ¸…æ™°çš„ Markdown æ ¼å¼è¾“å‡ºã€‚
    `;
  }

  const systemInstruction = "ä½ æ˜¯ä¸€ä¸ªæƒ³è±¡åŠ›ä¸°å¯Œçš„ä¸–ç•Œæ¶æ„å¸ˆã€‚è¯·æ ¹æ®ç”¨æˆ·çš„çµæ„Ÿç¢ç‰‡æ„å»ºé€»è¾‘è‡ªæ´½ä¸”ç²¾ç‚¼çš„å°è¯´ä¸–ç•Œè§‚ã€‚";

  try {
    if (modelConfig.provider === 'gemini') {
      initializeGemini(modelConfig.apiKey);
      if (!geminiClient) throw new Error("API Key missing.");

      const response = await retryWithBackoff(() => geminiClient!.models.generateContent({
        model: modelConfig.modelName || 'gemini-2.5-flash',
        contents: finalPrompt,
        config: {
          systemInstruction,
          temperature: 0.9,
          maxOutputTokens: 2048,
        }
      }));
      return typeof (response as any).text === 'function' ? (response as any).text() : ((response as any).text || "");
    } else {
      return await callOpenAICompatible(modelConfig, [{ role: 'user', content: finalPrompt }], systemInstruction);
    }
  } catch (error) {
    throw new Error(`ç”Ÿæˆå¤±è´¥: ${(error as Error).message}`);
  }
};

export const generateDetailedWorldview = async (
  modelConfig: ModelConfig,
  context: {
    storyLength?: string;
    core?: string;
    synopsis?: string;
    genre?: string;
    background?: string;
  },
  customTemplate?: string
): Promise<string> => {
  const lengthLabel = context.storyLength === 'short' ? 'çŸ­ç¯‡æ•…äº‹' : 'é•¿ç¯‡å°è¯´';

  const prompt = customTemplate
    ? customTemplate.replace('{{storyLength}}', lengthLabel)
    : `
      åŸºäºä»¥ä¸‹æ•…äº‹ä¿¡æ¯ï¼Œè®¾è®¡ä¸€ä¸ªç²¾ç‚¼ä¸”é€»è¾‘è‡ªæ´½çš„ä¸–ç•Œè§‚èƒŒæ™¯ã€‚
      
      ã€æ•…äº‹ç¯‡å¹…ã€‘ï¼š${lengthLabel}
      ã€æ•…äº‹å†…æ ¸ã€‘ï¼š${context.core || 'æœªè®¾å®š'}
      ã€æ•…äº‹æ¦‚è¦ã€‘ï¼š${context.synopsis || 'æœªè®¾å®š'}
      ã€åˆæ­¥è®¾å®šã€‘ï¼šç±»å‹ï¼š${context.genre || 'æœªæŒ‡å®š'}ï¼ŒåŸºç¡€èƒŒæ™¯ï¼š${context.background || 'æœªæŒ‡å®š'}
      
      è¦æ±‚åŒ…å«ä»¥ä¸‹å†…å®¹ï¼ˆè¯·ä¿æŒç®€æ˜æ‰¼è¦ï¼Œé¿å…å†—é•¿ï¼‰ï¼š
      1. ä¸–ç•ŒèƒŒæ™¯ï¼šç®€è¿°æ•…äº‹å‘ç”Ÿçš„ç©ºé—´è®¾å®šã€‚
      2. åŠ›é‡/æŠ€æœ¯ä½“ç³»ï¼šæ¦‚æ‹¬æ ¸å¿ƒé€»è¾‘ï¼ˆå¦‚ä¿®ä»™ç­‰çº§ã€ç§‘æŠ€æ°´å¹³ã€é­”æ³•æ³•åˆ™ç­‰ï¼‰ã€‚
      3. æ ¸å¿ƒå†²çªæºï¼šç‚¹å‡ºå¯¼è‡´æ•…äº‹å‘ç”Ÿçš„æ·±å±‚è¯±å› ã€‚
      
      è¯·ä½¿ç”¨ç»“æ„æ¸…æ™°çš„ Markdown æ ¼å¼è¾“å‡ºï¼Œé‡ç‚¹åœ¨äºæ ¸å¿ƒè®¾å®šçš„æ„å»ºï¼Œéæ ¸å¿ƒç»†èŠ‚å¯é€‚å½“ç•™ç™½ã€‚
    `;

  const systemInstruction = "ä½ æ˜¯ä¸€ä¸ªæƒ³è±¡åŠ›ä¸°å¯Œä¸”é€»è¾‘ä¸¥å¯†çš„ä¸–ç•Œæ¶æ„å¸ˆã€‚è¯·ä¸ºå°è¯´æ„å»ºé€»è¾‘è‡ªæ´½ä¸”ç²¾ç‚¼çš„ä¸–ç•Œè§‚ã€‚";

  try {
    if (modelConfig.provider === 'gemini') {
      initializeGemini(modelConfig.apiKey);
      if (!geminiClient) throw new Error("API Key missing.");

      const response = await retryWithBackoff(() => geminiClient!.models.generateContent({
        model: modelConfig.modelName || 'gemini-2.5-flash',
        contents: prompt,
        config: {
          systemInstruction,
          temperature: 0.9,
          maxOutputTokens: 2048,
        }
      }));
      return typeof (response as any).text === 'function' ? (response as any).text() : ((response as any).text || "");
    } else {
      return await callOpenAICompatible(modelConfig, [{ role: 'user', content: prompt }], systemInstruction);
    }
  } catch (error) {
    throw new Error(`ç”Ÿæˆä¸–ç•Œè§‚å¤±è´¥: ${(error as Error).message}`);
  }
};

export const generateOutlineFromWorldview = async (
  modelConfig: ModelConfig,
  worldview: string,
  spark: string,
  customTemplate?: string
): Promise<string> => {
  let finalPrompt = '';

  if (customTemplate) {
    finalPrompt = customTemplate
      .replace(/{{worldview}}/g, worldview || "ï¼ˆæš‚æ— è¯¦ç»†è®¾å®šï¼Œè¯·æ ¹æ®æ ¸å¿ƒæ¢—è‡ªç”±å‘æŒ¥ï¼‰")
      .replace(/{{spark}}/g, spark)
      .replace(/{{input}}/g, spark);
  } else {
    // åŠ¨æ€æ„å»º Promptï¼Œå¦‚æœ worldview ä¸ºç©ºåˆ™ä¸å¼ºè°ƒå®ƒ
    const worldviewSection = worldview ? `ã€ä¸–ç•Œè§‚è®¾å®šã€‘ï¼š${worldview}` : '';

    finalPrompt = `
      ã€æ ¸å¿ƒæ¢—ã€‘ï¼š${spark}
      ${worldviewSection}

      è¯·åŸºäºä»¥ä¸Šä¿¡æ¯ï¼Œè®¾è®¡ä¸€ä¸ªæ ‡å‡†çš„ä¸‰å¹•å¼å°è¯´å¤§çº²ã€‚
      è¦æ±‚ï¼š
      1. ä¸»è§’èƒŒæ™¯è®¾å®šï¼ˆåº•å±‚è´«æ°‘/æ„å¤–å·å…¥è€…ç­‰ï¼‰ã€‚
      2. æ¯ä¸€å¹•ï¼ˆç¬¬ä¸€å·ã€ç¬¬äºŒå·ã€ç¬¬ä¸‰å·ï¼‰çš„æ ¸å¿ƒå†²çªå’Œé«˜æ½®ç‚¹ã€‚
      3. ç»“å±€çš„åˆæ­¥æ„æƒ³ã€‚
      
      è¯·ç”¨ Markdown æ ¼å¼è¾“å‡ºã€‚
    `;
  }

  const systemInstruction = "ä½ æ˜¯ä¸€ä¸ªæ“…é•¿æ„å»ºå‰§æƒ…ç»“æ„çš„å°è¯´ä¸»ç¼–ã€‚è¯·è®¾è®¡æƒ…èŠ‚ç´§å‡‘ã€å†²çªæ¿€çƒˆçš„å¤§çº²ã€‚";

  try {
    if (modelConfig.provider === 'gemini') {
      initializeGemini(modelConfig.apiKey);
      if (!geminiClient) throw new Error("API Key missing.");

      const response = await retryWithBackoff(() => geminiClient!.models.generateContent({
        model: modelConfig.modelName || 'gemini-2.5-flash',
        contents: finalPrompt,
        config: {
          systemInstruction,
          temperature: 0.7,
        }
      }));
      return response.text || "æœªèƒ½ç”Ÿæˆå¤§çº²ã€‚";
    } else {
      return await callOpenAICompatible(
        modelConfig,
        [{ role: 'user', content: finalPrompt }],
        systemInstruction
      );
    }
  } catch (error) {
    throw new Error(`ç”Ÿæˆå¤§çº²å¤±è´¥: ${(error as Error).message}`);
  }
};

export const generateChapterBeatsFromOutline = async (
  modelConfig: ModelConfig,
  outline: string,
  customTemplate?: string
): Promise<ChapterBeat[]> => {
  let promptContent = '';

  if (customTemplate) {
    promptContent = customTemplate
      .replace(/{{outline}}/g, outline)
      .replace(/{{input}}/g, outline);
  } else {
    promptContent = `
      ã€å°è¯´å¤§çº²ã€‘ï¼š${outline}

      è¯·åŸºäºå¤§çº²çš„ç¬¬ä¸€éƒ¨åˆ†ï¼ˆç¬¬ä¸€å·ï¼‰ï¼Œæ‹†åˆ†ä¸º 5-8 ä¸ªå…·ä½“çš„ç« èŠ‚ç»†çº²ã€‚
    `;
  }

  const finalPrompt = `
    ${promptContent}
    
    IMPORTANT:
    è¯·ä¸¥æ ¼è¿”å› JSON æ ¼å¼ï¼Œæ•°ç»„ç»“æ„ï¼Œä¸è¦åŒ…å« markdown ä»£ç å—æ ‡è®°ã€‚æ ¼å¼å¦‚ä¸‹ï¼š
    [
      {
        "chapterTitle": "ç¬¬ä¸€ç« ï¼šå…·ä½“æ ‡é¢˜",
        "summary": "ç¬¬ä¸€ç« çš„å…·ä½“äº‹ä»¶æ‘˜è¦...",
        "keyCharacters": ["ä¸»è§’å", "é…è§’å"],
        "conflict": "æ ¸å¿ƒå†²çªç‚¹"
      },
      {
        "chapterTitle": "ç¬¬äºŒç« ï¼šå…·ä½“æ ‡é¢˜",
        "summary": "ç¬¬äºŒç« çš„å…·ä½“äº‹ä»¶æ‘˜è¦...",
        "keyCharacters": ["ä¸»è§’å", "é…è§’å"],
        "conflict": "æ ¸å¿ƒå†²çªç‚¹"
      }
    ]
  `;

  const systemInstruction = "ä½ æ˜¯ä¸€ä¸ªç²¾é€šç½‘æ–‡èŠ‚å¥çš„ç­–åˆ’ã€‚è¯·å°†å¤§çº²æ‹†è§£ä¸ºå…·è±¡åŒ–çš„ç« èŠ‚ç»†çº²ã€‚ä»…è¿”å›çº¯ JSON æ•°æ®ã€‚è¯·ç¡®ä¿æ¯ä¸€ç« çš„å†…å®¹éƒ½æ˜¯ç‹¬ç‰¹çš„ï¼Œä¸è¦é‡å¤ç›¸åŒçš„å¤§çº²ã€‚";

  try {
    let text = '';

    if (modelConfig.provider === 'gemini') {
      initializeGemini(modelConfig.apiKey);
      if (!geminiClient) throw new Error("API Key missing.");

      const response = await retryWithBackoff(() => geminiClient!.models.generateContent({
        model: modelConfig.modelName || 'gemini-2.5-flash',
        contents: finalPrompt,
        config: {
          systemInstruction,
          temperature: 0.6,
          maxOutputTokens: 8192,
          responseMimeType: "application/json"
        }
      }));
      text = response.text || "[]";
    } else {
      const configWithHighTokens = { ...modelConfig, maxTokens: Math.max(modelConfig.maxTokens || 4096, 8192) };
      const result = await callOpenAICompatible(
        configWithHighTokens,
        [{ role: 'user', content: finalPrompt }],
        systemInstruction
      );
      text = result;
    }

    // Clean up potential markdown code blocks
    let jsonStr = text.replace(/```json\n?|\n?```/g, '').trim();

    const arrayMatch = jsonStr.match(/\[[\s\S]*\]/);
    if (arrayMatch) {
      jsonStr = arrayMatch[0];
    }

    try {
      return JSON.parse(jsonStr) as ChapterBeat[];
    } catch (e) {
      console.error("JSON Parse Error. Raw:", text);
      throw new Error("AI è¿”å›æ•°æ®æ— æ³•è§£æï¼Œè¯·é‡è¯•ã€‚");
    }
  } catch (error) {
    console.error("JSON Parse Error or AI Error", error);
    throw new Error("ç”Ÿæˆç»†çº²å¤±è´¥æˆ–æ ¼å¼è§£æé”™è¯¯ã€‚");
  }
};

// ä»å·å†…å®¹æ‹†åˆ†æŒ‡å®šæ•°é‡çš„ç« èŠ‚ç»†çº²
export const generateBeatsFromVolumeContent = async (
  modelConfig: ModelConfig,
  context: {
    volumeContent: string;
    chapterCount: number;
    startChapter: number;
    spark?: string;
    core?: string;
    synopsis?: string;
    worldview?: string;
    characters?: CharacterProfile[];
    referenceContext?: string; // New: Context from reference chapters
  },
  customTemplate?: string
): Promise<ChapterBeat[]> => {
  let promptContent = '';

  const { volumeContent, chapterCount, startChapter, referenceContext } = context;

  // ä¼˜åŒ–è§’è‰²æ•°æ®å±•ç°ï¼ŒåŒ…å«æ›´å¤šç»´åº¦
  const optimizedCharacters = context.characters?.map(c =>
    `### ${c.name} (${c.role})\n- æ€§æ ¼: ${c.personality || 'æš‚æ— '}\n- ç®€ä»‹: ${c.description || 'æš‚æ— '}\n- èƒŒæ™¯: ${c.background || 'æš‚æ— '}`
  ).join('\n') || "æš‚æ— å…·ä½“è§’è‰²è®¾å®š";

  const contextBlock = `
--- æ•…äº‹åŸºç¡€è®¾å®š (æ ¸å¿ƒ) ---
ã€æ ¸å¿ƒçµæ„Ÿã€‘ï¼š${context.spark || 'æœªæä¾›'}
ã€æ•…äº‹å†…æ ¸ã€‘ï¼š${context.core || 'æœªæä¾›'}
ã€æ•…äº‹æ¦‚è¦ã€‘ï¼š${context.synopsis || 'æœªæä¾›'}

--- ä¸–ç•Œè§‚è®¾å®š ---
${context.worldview ? context.worldview.slice(0, 2000) : 'æš‚æ— è¯¦ç»†è®¾å®š'}

--- æ ¸å¿ƒè§’è‰²é˜µå®¹ ---
${optimizedCharacters}

${referenceContext ? `--- å‰æ–‡å‰§æƒ…å‚è€ƒ/æ‰¿æ¥ä¸Šä¸‹æ–‡ ---\n${referenceContext}` : ''}
  `.trim();

  if (customTemplate) {
    promptContent = customTemplate
      .replace(/{{volumeContent}}/g, volumeContent)
      .replace(/{{input}}/g, volumeContent)
      .replace(/{{chapterCount}}/g, String(chapterCount))
      .replace(/{{startChapter}}/g, String(startChapter))
      .replace(/{{reference}}/g, referenceContext || '');
  } else {
    promptContent = `
      ${contextBlock}

      --- å¾…æ‹†è§£çš„å‰§æƒ…æ–‡æœ¬ ---
      ${volumeContent}

      --- ä»»åŠ¡æ ¸å¿ƒæŒ‡ä»¤ (CRITICAL) ---
      ä½ å½“å‰çš„è§’è‰²æ˜¯èµ„æ·±ç½‘æ–‡æ¶æ„å¸ˆã€‚è¯·å°†ä¸Šè¿°ã€å¾…æ‹†è§£çš„å‰§æƒ…æ–‡æœ¬ã€‘æ‹†åˆ†ä¸º ${chapterCount} ä¸ªè¿ç»­çš„ç« èŠ‚ç»†çº²ã€‚
      
      ã€å¼ºåˆ¶è¦æ±‚ã€‘ï¼š
      1. **è®¾å®šä¸€è‡´æ€§**ï¼šå‰§æƒ…é€»è¾‘ã€åŠ›é‡ä½“ç³»ã€äººç‰©è¡Œä¸ºæ¨¡å¼å¿…é¡» 100% ç¬¦åˆä¸Šæ–‡æä¾›çš„ã€ä¸–ç•Œè§‚ã€‘å’Œã€è§’è‰²é˜µå®¹ã€‘è®¾å®šï¼Œä¸¥ç¦é€»è¾‘ç›¸æ‚–ã€‚
      2. **æ‰¿æ¥ç²¾å‡†æ€§**ï¼šå¦‚æœå­˜åœ¨ã€å‰æ–‡å‰§æƒ…å‚è€ƒã€‘ï¼Œè¯·ç¡®ä¿ç¬¬ ${startChapter} ç« ä¸å‰æ–‡æ— ç¼è¡”æ¥ï¼Œäººç‰©çŠ¶æ€å¿…é¡»è¿è´¯ã€‚
      3. **ç« èŠ‚ç»†åŒ–**ï¼šæ¯ä¸€ç« éœ€æ‹†è§£ä¸º 5-6 ä¸ªå…·ä½“çš„å¯¹è¯åœºæ™¯ï¼Œå¹¶è§„åˆ’åˆç†çš„å­—æ•°ã€‚
      4. **ä¸¥ç¦åˆå¹¶**ï¼šå¿…é¡»è¿”å›æ°å¥½ ${chapterCount} ä¸ªç« èŠ‚ï¼ˆä»ç¬¬ ${startChapter} ç« åˆ°ç¬¬ ${startChapter + chapterCount - 1} ç« ï¼‰ã€‚
      5. **æ‹’ç»å¹»è§‰**ï¼šä¸è¦å¼•å…¥ä¸å·²æœ‰ä¸–ç•Œè§‚å†²çªçš„å¥‡å¹»/ç§‘å¹»å…ƒç´ ï¼Œä¸è¦éšæ„æ›´æ”¹è§’è‰²æ€§æ ¼ã€‚
    `;
  }

  const finalPrompt = `
    ${promptContent}
    
    --- è¾“å‡ºè§„èŒƒ ---
    è¯·ä¸¥æ ¼è¿”å› JSON æ•°ç»„æ ¼å¼ï¼Œä¸è¦åŒ…å«ä»»ä½• markdown ä»£ç å—æ ‡è®°ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
    [
      {
        "chapterTitle": "ç¬¬${startChapter}ç« ï¼šå…·ä½“æ ‡é¢˜",
        "summary": "æœ¬ç« çš„å…·ä½“äº‹ä»¶æ‘˜è¦...",
        "keyCharacters": ["ä¸»è§’å", "é…è§’å"],
        "conflict": "æ ¸å¿ƒå†²çªç‚¹",
        "scenes": [
          {
             "sceneTitle": "åœºæ™¯ä¸€ï¼šåœºæ™¯å",
             "detail": "å…³é”®çº¿ç´¢æˆ–å†²çªç‚¹æè¿°...",
             "wordCount": "400å­—"
          },
          ...
        ]
      },
      ...
    ]
  `;

  const systemInstruction = `ä½ æ˜¯ä¸€ä¸ªæ·±è€•ç½‘æ–‡åˆ›ä½œçš„ AI åŠ©æ‰‹ã€‚ä½ æå…¶æ“…é•¿é€»è¾‘æ¨æ¼”å’Œç»†èŠ‚ä¸°æ»¡ã€‚
ä½ çš„å®ˆåˆ™ï¼š
1. é€»è¾‘é‡äºä¸€åˆ‡ï¼šå¿…é¡»ä¸¥æ ¼åŸºäºç”¨æˆ·æä¾›çš„ã€æ•…äº‹å†…æ ¸ã€‘ã€ã€ä¸–ç•Œè§‚ã€‘å’Œã€è§’è‰²å°ä¼ ã€‘è¿›è¡Œç»†åŒ–ï¼Œç»å¯¹ä¸å…è®¸èƒŒç¦»è®¾å®šã€‚
2. é£æ ¼åŒ¹é…ï¼šä¿æŒä¸å‚è€ƒå†…å®¹çš„è¯­å¢ƒä¸€è‡´ã€‚
3. ä¸¥æ ¼éµå¾ªè¾“å‡ºæ•°é‡è¦æ±‚ï¼šç”¨æˆ·è¦æ±‚ ${chapterCount} ç« ï¼Œå°±å¿…é¡»ç”Ÿæˆ ${chapterCount} ç« ã€‚
4. ä»…è¾“å‡ºçº¯ JSON æ•°æ®ï¼Œç¦æ­¢ä»»ä½•åºŸè¯ã€‚`;

  try {
    let text = '';

    if (modelConfig.provider === 'gemini') {
      initializeGemini(modelConfig.apiKey);
      if (!geminiClient) throw new Error("API Key missing.");

      const response = await retryWithBackoff(() => geminiClient!.models.generateContent({
        model: modelConfig.modelName || 'gemini-2.5-flash',
        contents: finalPrompt,
        config: {
          systemInstruction,
          temperature: 0.7, // Slightly higher temp for creative splitting
          maxOutputTokens: 8192,
          responseMimeType: "application/json"
        }
      }));
      text = response.text || "[]";
    } else {
      const configWithHighTokens = { ...modelConfig, maxTokens: Math.max(modelConfig.maxTokens || 4096, 8192) };
      const result = await callOpenAICompatible(
        configWithHighTokens,
        [{ role: 'user', content: finalPrompt }],
        systemInstruction
      );
      text = result;
    }

    // Clean up potential markdown code blocks
    let jsonStr = text.replace(/```json\n?|\n?```/g, '').trim();

    // Attempt to extract JSON array
    const arrayMatch = jsonStr.match(/\[[\s\S]*\]/);
    if (arrayMatch) {
      jsonStr = arrayMatch[0];
    }

    try {
      return JSON.parse(jsonStr) as ChapterBeat[];
    } catch (parseError) {
      console.warn("Initial JSON parse failed, attempting iterative recovery for truncated JSON...");

      // Iterative Recovery Logic:
      // Repeatedly try to cut off the last '}' and append ']' until valid JSON is formed.
      // This effectively discards incomplete nested structures or incomplete last items.
      let currentStr = jsonStr;
      let attempts = 0;
      const MAX_ATTEMPTS = 50; // Prevent infinite loops for very large or malformed strings

      while (currentStr.lastIndexOf('}') !== -1 && attempts < MAX_ATTEMPTS) {
        attempts++;
        const lastBraceIdx = currentStr.lastIndexOf('}');

        // Keep everything up to this last brace
        currentStr = currentStr.substring(0, lastBraceIdx + 1);
        const attemptStr = currentStr + ']';

        try {
          const recoveredData = JSON.parse(attemptStr) as ChapterBeat[];
          console.log(`JSON recovery successful after ${attempts} attempts. Items recovered:`, recoveredData.length);
          return recoveredData;
        } catch (e) {
          // If this attempt failed, strip the last brace we just tried and continue searching backwards
          currentStr = currentStr.substring(0, currentStr.length - 1);
        }
      }

      console.error("JSON Parse Error. Raw Text:", text);
      throw new Error(`AI è¿”å›æ ¼å¼é”™è¯¯ï¼Œæ— æ³•è§£æç»†çº²æ•°æ®ã€‚`);
    }
  } catch (error) {
    console.error("JSON Parse Error or AI Error", error);
    throw new Error("ç”Ÿæˆç»†çº²å¤±è´¥æˆ–æ ¼å¼è§£æé”™è¯¯ã€‚");
  }
};

export const generateCharactersFromIdea = async (
  modelConfig: ModelConfig,
  context: {
    spark: string;
    core?: string;
    synopsis?: string;
    worldview?: string;
    requirements?: {
      protagonist: number;
      antagonist: number;
      supporting: number;
    };
  },
  customTemplate?: string
): Promise<Omit<CharacterProfile, 'id'>[]> => {
  let promptContent = '';

  const { requirements } = context;
  const countReq = requirements
    ? `è¯·ä¸¥æ ¼ç”Ÿæˆä»¥ä¸‹æ•°é‡çš„è§’è‰²ï¼šä¸»è§’ ${requirements.protagonist} äººï¼Œåæ´¾ ${requirements.antagonist} äººï¼Œé‡è¦é…è§’ ${requirements.supporting} äººã€‚`
    : "è¯·åŸºäºä»¥ä¸Šæ•…äº‹è®¾å®šï¼Œè®¾è®¡ 3-5 ä¸ªæ ¸å¿ƒè§’è‰²ï¼ˆåŒ…æ‹¬ä¸»è§’å’Œå…³é”®é…è§’/åæ´¾ï¼‰ã€‚";

  if (customTemplate) {
    promptContent = customTemplate
      .replace(/{{spark}}/g, context.spark)
      .replace(/{{core}}/g, context.core || '')
      .replace(/{{synopsis}}/g, context.synopsis || '')
      .replace(/{{worldview}}/g, context.worldview || '')
      .replace(/{{input}}/g, context.synopsis || context.spark);
  } else {
    promptContent = `
      ã€çµæ„Ÿ/è„‘æ´ã€‘ï¼š${context.spark}
      ${context.core ? `ã€æ•…äº‹å†…æ ¸ã€‘ï¼š${context.core}` : ''}
      ${context.synopsis ? `ã€æ•…äº‹æ¦‚è¦ã€‘ï¼š${context.synopsis}` : ''}
      ${context.worldview ? `ã€ä¸–ç•Œè§‚è®¾å®šã€‘ï¼š${context.worldview}` : ''}

            ${countReq}
            
            è¦æ±‚ï¼š
            1. è§’è‰²æ€§æ ¼è¦é²œæ˜ï¼Œæœ‰ç‹¬ç‰¹çš„è¾¨è¯†åº¦ã€‚
            2. è§’è‰²èƒŒæ™¯è¦ä¸ä¸–ç•Œè§‚æ·±åº¦ç»“åˆã€‚
            3. è§’è‰²ä¹‹é—´è¦æœ‰å……æ»¡å¼ åŠ›çš„å…³ç³»ã€‚
            4. è¯·ç²¾ç®€è¾“å‡ºï¼Œã€èƒŒæ™¯æ•…äº‹ã€‘å’Œã€æ€§æ ¼æè¿°ã€‘è¯·ä¸¥æ ¼æ§åˆ¶åœ¨ 100 å­—ä»¥å†…ï¼Œé¿å…è¿‡é•¿å¯¼è‡´å†…å®¹æˆªæ–­ã€‚
          `;
  }

  const finalPrompt = `
          ${promptContent}
          
          IMPORTANT:
          è¯·ä¸¥æ ¼è¿”å› JSON æ ¼å¼ï¼Œæ•°ç»„ç»“æ„ï¼Œä¸è¦åŒ…å« markdown ä»£ç å—æ ‡è®°ã€‚æ ¼å¼å¦‚ä¸‹ï¼š
          [
            {
              "name": "è§’è‰²å",
              "role": "ä¸»è§’/åæ´¾/é‡è¦é…è§’",
              "gender": "ç”·/å¥³/å…¶ä»–",
              "age": "å¹´é¾„æˆ–è§†è§‰å¹´é¾„",
              "description": "ç®€çŸ­çš„ä¸€å¥è¯ä»‹ç»",
              "personality": "è¯¦ç»†çš„æ€§æ ¼æè¿°(100å­—å†…)...",
              "appearance": "è¯¦ç»†çš„å¤–è²Œæå†™...",
              "background": "è¯¦ç»†çš„è§’è‰²èƒŒæ™¯æ•…äº‹(100å­—å†…)..."
            },
            ...
          ]
        `;

  const systemInstruction = "ä½ æ˜¯ä¸€ä¸ªæ“…é•¿åˆ›é€ é²œæ´»è§’è‰²çš„äººç‰©è®¾è®¡å¸ˆã€‚è¯·è®¾è®¡æœ‰è¡€æœ‰è‚‰ã€åŠ¨æœºåˆç†çš„è§’è‰²ã€‚ä»…è¿”å›çº¯ JSON æ•°æ®ã€‚";

  try {
    let text = '';

    if (modelConfig.provider === 'gemini') {
      initializeGemini(modelConfig.apiKey);
      if (!geminiClient) throw new Error("API Key missing.");

      const response = await retryWithBackoff(() => geminiClient!.models.generateContent({
        model: modelConfig.modelName || 'gemini-2.5-flash',
        contents: finalPrompt,
        config: {
          systemInstruction,
          temperature: 0.8,
          maxOutputTokens: 8192,
          responseMimeType: "application/json"
        }
      }));
      text = response.text || "[]";
    } else {
      const result = await callOpenAICompatible(
        modelConfig,
        [{ role: 'user', content: finalPrompt }],
        systemInstruction
      );
      text = result;
    }

    // Clean up potential markdown code blocks and whitespace
    let jsonStr = text.replace(/```json\n?|\n?```/g, '').trim();

    // Ensure start from the first bracket
    const startIdx = jsonStr.indexOf('[');
    if (startIdx !== -1) {
      jsonStr = jsonStr.substring(startIdx);
    }

    try {
      return JSON.parse(jsonStr) as Omit<CharacterProfile, 'id'>[];
    } catch (parseError) {
      console.warn("Initial JSON parse failed, attempting recovery for truncated JSON...");

      // Recovery Logic: Try to find the last closing brace '}' and close the array
      const lastBraceIdx = jsonStr.lastIndexOf('}');
      if (lastBraceIdx !== -1) {
        // Take everything up to the last object end, and assume it's an array that needs closing
        const recoveredStr = jsonStr.substring(0, lastBraceIdx + 1) + ']';
        try {
          const recoveredData = JSON.parse(recoveredStr) as Omit<CharacterProfile, 'id'>[];
          console.log("JSON recovery successful. Items recovered:", recoveredData.length);
          return recoveredData;
        } catch (recoveryError) {
          console.error("JSON recovery failed.");
        }
      }

      console.error("JSON Parse Error. Raw Text:", text);
      throw new Error(`AI è¿”å›æ ¼å¼é”™è¯¯ï¼Œæ— æ³•è§£æè§’è‰²æ•°æ®ã€‚åŸå§‹å“åº”ç‰‡æ®µ: ${text.slice(0, 100)}...`);
    }
  } catch (error) {
    console.error("Generate Characters Error:", error);
    throw new Error(`ç”Ÿæˆè§’è‰²å¤±è´¥: ${(error as Error).message}`);
  }
};

export const generateCompleteOutline = async (
  modelConfig: ModelConfig,
  data: {
    spark: string;
    core?: string;
    synopsis?: string;
    storyline?: string;
    worldview?: string;
    characters?: CharacterProfile[];
  },
  customTemplate?: string
): Promise<string> => {
  // 1. Optimize Character Data (Token Reduction Strategy)
  const optimizedCharacters = data.characters?.map(c =>
    `- ${c.name} (${c.role}): ${c.description} [æ€§æ ¼æ ¸å¿ƒ: ${c.personality?.slice(0, 50) || 'æœªè®¾å®š'}]`
  ).join('\n') || "æš‚æ— å…·ä½“è§’è‰²è®¾å®š";

  // 2. Construct the Context
  let finalPrompt = '';

  const contextBlock = `
          ã€æ ¸å¿ƒçµæ„Ÿã€‘ï¼š${data.spark}
          ${data.core ? `ã€æ•…äº‹å†…æ ¸ã€‘ï¼š${data.core}` : ''}
          ${data.synopsis ? `ã€æ•…äº‹æ¦‚è¦ã€‘ï¼š${data.synopsis}` : ''}
          
          ã€ä¸–ç•Œè§‚è§„åˆ™ã€‘ï¼š
          ${data.worldview ? data.worldview.slice(0, 1000) + (data.worldview.length > 1000 ? '...(ç•¥)' : '') : 'æš‚æ— è¯¦ç»†è®¾å®š'}
          
          ã€æ ¸å¿ƒè§’è‰²é˜µå®¹ã€‘ï¼š
          ${optimizedCharacters}
          
          ${data.storyline ? `ã€å‚è€ƒæ•…äº‹çº¿ã€‘ï¼š\n${data.storyline}` : ''}
            `.trim();

  if (customTemplate) {
    finalPrompt = customTemplate
      .replace(/{{context}}/g, contextBlock)
      .replace(/{{spark}}/g, data.spark)
      .replace(/{{storyline}}/g, data.storyline || '')
      .replace(/{{worldview}}/g, data.worldview || '')
      .replace(/{{characters}}/g, optimizedCharacters);
  } else {
    finalPrompt = `
                ${contextBlock}
          
                --- ä»»åŠ¡æŒ‡ä»¤ ---
                è¯·ç»¼åˆä»¥ä¸Šç´ æï¼Œåˆ›ä½œä¸€ä»½è¯¦å°½çš„**å…¨ä¹¦å¤§çº²**ã€‚
                
                **è¾“å‡ºæ ¼å¼è¦æ±‚ï¼ˆå¿…é¡»ä¸¥æ ¼éµå®ˆï¼‰**ï¼š
                
                # å…¨ä¹¦å¤§çº²
                
                ## ä¸€ã€æ•…äº‹ä¸»çº¿
                ï¼ˆåœ¨æ­¤å¤„ç”¨ç²¾ç‚¼çš„è¯­è¨€æ¦‚æ‹¬è´¯ç©¿å…¨ä¹¦çš„æ ¸å¿ƒå‰§æƒ…çº¿ç´¢ï¼Œçº¦300-500å­—ã€‚ï¼‰
                
                ## äºŒã€åˆ†å·ç»†çº²
                
                ### ç¬¬ä¸€å·ï¼š[å·å]
                **ä¸»è¦å†…å®¹**ï¼š
                ï¼ˆè¯¦ç»†æè¿°æœ¬å·çš„ä¸»çº¿å‰§æƒ…å‘å±•ï¼Œæ ¸å¿ƒå†²çªä¸é«˜æ½®ã€‚ï¼‰
                **æ”¯çº¿å†…å®¹**ï¼š
                ï¼ˆæè¿°æœ¬å·å¹¶è¡Œçš„æ”¯çº¿å‰§æƒ…ï¼Œå¦‚é…è§’æˆé•¿ã€æ„Ÿæƒ…çº¿ã€éšè—ä¼ç¬”ç­‰ã€‚ï¼‰
                
                ### ç¬¬äºŒå·ï¼š[å·å]
                **ä¸»è¦å†…å®¹**ï¼š...
                **æ”¯çº¿å†…å®¹**ï¼š...
                
                ï¼ˆåç»­åˆ†å·ä»¥æ­¤ç±»æ¨...ï¼‰
                
                **å†…å®¹è¦æ±‚**ï¼š
                1. **æ·±åº¦èåˆ**ï¼šå‰§æƒ…å¿…é¡»ä½“ç°ã€è§’è‰²ã€‘çš„æ€§æ ¼ç‰¹å¾å’Œã€ä¸–ç•Œè§‚ã€‘çš„ç‹¬ç‰¹è§„åˆ™ã€‚
                2. **ç»“æ„ä¸¥è°¨**ï¼šé‡‡ç”¨åˆ†å·ç»“æ„ï¼Œç¡®ä¿æ¯ä¸€å·éƒ½æœ‰æ˜ç¡®çš„èµ·æ‰¿è½¬åˆã€‚
                3. **ä¸»æ¬¡åˆ†æ˜**ï¼šä¸»è¦å†…å®¹è¦ç´§æ‰£æ ¸å¿ƒå†²çªï¼Œæ”¯çº¿å†…å®¹è¦ä¸°å¯Œä¸–ç•Œè§‚å’Œäººç‰©å…³ç³»ã€‚
                
                è¯·ä»¥ Markdown æ ¼å¼è¾“å‡ºã€‚
              `;
  }

  const systemInstruction = "ä½ æ˜¯ä¸€ä¸ªæ“…é•¿ç»“æ„å¸ƒå±€çš„å°è¯´ä¸»ç¼–ã€‚è¯·æ ¹æ®ç°æœ‰ç´ æï¼Œç¼–ç»‡å‡ºä¸»çº¿æ¸…æ™°ã€æ”¯çº¿ä¸°å¯Œã€é€»è¾‘ä¸¥å¯†çš„å¤§çº²ã€‚";

  try {
    if (modelConfig.provider === 'gemini') {
      initializeGemini(modelConfig.apiKey);
      if (!geminiClient) throw new Error("API Key missing.");

      const response = await retryWithBackoff(() => geminiClient!.models.generateContent({
        model: modelConfig.modelName || 'gemini-2.5-flash',
        contents: finalPrompt,
        config: {
          systemInstruction,
          temperature: 0.7,
          maxOutputTokens: 8192,
        }
      }));
      return response.text || "æœªèƒ½ç”Ÿæˆå¤§çº²ã€‚";
    } else {
      // Ensure sufficient tokens for full outline
      const configWithHighTokens = { ...modelConfig, maxTokens: Math.max(modelConfig.maxTokens || 4096, 8192) };
      return await callOpenAICompatible(
        configWithHighTokens,
        [{ role: 'user', content: finalPrompt }],
        systemInstruction
      );
    }
  } catch (error) {
    console.error("Generate Outline Error:", error);
    throw new Error(`ç”Ÿæˆå¤§çº²å¤±è´¥: ${(error as Error).message}`);
  }
};
